# -*- coding: utf-8 -*-
"""schools_use.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_WGGXqzDC0s3s4L-RQNaFUl0fCOyBfEl
"""

!pip install fuzzywuzzy

import pandas as pd
import fuzzywuzzy
from fuzzywuzzy import fuzz
from fuzzywuzzy import process
from collections import Counter
import numpy as np

public_df = pd.read_excel('Enrolment Public School.xlsx',sheet_name='Sheet2')
schools_gps =pd.read_excel('schools_gps.xlsx',sheet_name='schools_gps')

public_df['sch_grade'] = np.nan
public_df['sch_grade'] = np.where(public_df.sch_type == 'LBS','Lower Basic School', public_df.sch_grade)
public_df['sch_grade'] = np.where(public_df.sch_type == 'UBS','Upper Basic School', public_df.sch_grade)
public_df['sch_grade'] = np.where(public_df.sch_type == 'SSS','Senior Secondary School', public_df.sch_grade)
public_df['sch_grade'] = np.where(public_df.sch_type == 'BCS','Basic Cycle School', public_df.sch_grade)
schools_gps['sch_name'] = np.where(schools_gps.sch_name.str.contains(pat=r'Serrekunda Primary School'),'Serekunda Primary School',schools_gps.sch_name)

public_df['sch_com'] = public_df.sch_name + ' ' + public_df.sch_grade

pop_cols = ['pop_male','pop_female','pop_total']
for col in pop_cols:
  public_df[col] = public_df[col].replace(to_replace ='...', value = '')
  public_df[col] = public_df[col].fillna('')

"""fuzz matching the school names of the 2 datasets"""

choices = public_df.sch_com.to_list()

def fm(row):
  matches = process.extract( row['sch_name'], choices)
  extractMatchBool = matches[0][1] == 100

  row['match 1'] = matches[0][0]
  row['match 1 sc'] = matches[0][1]

  row['match 2'] = '' if extractMatchBool else matches[1][0]
  row['match 2 sc'] = '' if extractMatchBool else matches[1][1]

  row['match 3'] = '' if extractMatchBool else matches[2][0]
  row['match 3 sc'] = '' if extractMatchBool else matches[2][1]

  return row

sch_pub = schools_gps.apply(fm, axis=1)

"""keep in is_pub if score >= 95 else in non_pub"""

is_pub = sch_pub[sch_pub['match 1 sc'] >=95]
non_pub = sch_pub[sch_pub['match 1 sc'] < 95]

is_pub=is_pub.drop(columns=['match 1 sc','match 2', 'match 2 sc', 'match 3', 'match 3 sc','sch_add1','sch_name'])
non_pub=non_pub.drop(columns=['match 1 sc','match 2', 'match 2 sc', 'match 3', 'match 3 sc','sch_add1'])

is_pub=is_pub.rename(columns={'match 1':'sch_com'})
non_pub=non_pub.rename(columns={'match 1':'sch_com'})

"""merge the lat and lng to the puublis dataset and append the columns without lat and lng from sch_gps to public sch dataset"""

df_final = pd.merge(public_df,is_pub,how='left',right_on='sch_com',left_on='sch_com').sort_values(by=['lat','lng']).drop_duplicates(subset=['sch_com'],ignore_index=True)

"""fuzzing matching within the school_gps dataset to identify similar strings"""

non_pub = non_pub[['sch_name', 'lat', 'lng']]
choices = non_pub.sch_name.to_list()

def fm(row):
  matches = process.extract( row['sch_name'], choices)
  extractMatchBool = matches[0][1] == 100

  row['match 1'] = matches[0][0]
  row['match 1 sc'] = matches[0][1]

  row['match 2'] = matches[1][0]
  row['match 2 sc'] = matches[1][1]
  
  return row

non_pub = non_pub.apply(fm, axis=1)

is_sch= non_pub[['sch_name','lat','lng','match 1','match 2','match 2 sc']][non_pub['match 2 sc'] <90]
non_sch= non_pub[['sch_name','lat','lng','match 1','match 2','match 2 sc']][non_pub['match 2 sc'] >=90]
non_sch['dedupe']= non_sch['match 2'].str.split()
non_sch['dedupe']= non_sch['match 2'].str.split(expand=True)[0]
non_sch =non_sch.drop_duplicates(subset=['dedupe'],ignore_index=True)
non_sch = non_sch.drop(columns=['match 1', 'match 2', 'match 2 sc', 'dedupe'])
is_sch = is_sch.drop(columns=['match 1', 'match 2', 'match 2 sc'])

"""merge the dedupe data"""

df_final = pd.concat([df_final,non_sch,is_sch],axis=0,ignore_index=True)
schools = df_final.drop(columns=['sch_grade','sch_com'])

pop_cols = ['pop_male','pop_female','pop_total']
for col in pop_cols:
  schools[col] = schools[col].replace(to_replace ='...', value = '')
  schools[col] = schools[col].fillna('')
  #schools[col] = schools[col].astype('int64')

for col in schools.select_dtypes('O'):
  schools[col] = schools[col].fillna('')

for col in ['lat','lng']:
  schools[col] = schools[col].astype('O')
  schools[col] = schools[col].fillna('')

schools.sch_code = schools.sch_code.astype('O')
schools.sch_code = schools.sch_code.fillna('')

for col in ['lat','lng']:
    schools[col] = pd.to_numeric(schools[col], errors='coerce').astype('float64')
for col in ['pop_total','pop_male','pop_female','scode']:
    schools[col] = pd.to_numeric(schools[col], errors='coerce').astype('Int64')

schools.to_excel('schools.xlsx', index=False)

schools.describe(include='all')

schools.sch_type.value_counts()

schools.shape[0]

